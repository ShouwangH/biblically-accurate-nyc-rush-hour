#!/usr/bin/env python3
"""
Route Cache Generation Script

Pre-computes route templates for the pseudo-trip traffic model.
Routes are generated by simulating the routing algorithm offline.

Implements §4B.2 from PSEUDO_TRIP_TRAFFIC_PLAN.md:
- Route simulation with length buckets
- Graph version hashing for cache invalidation
- Connectivity validation per route

Usage:
    python scripts/generate_route_cache.py

Output:
    public/assets/route_cache.json
"""

import json
import math
import random
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime

# =============================================================================
# Constants (from §4B.2 and §4.6)
# =============================================================================

# Route generation
ROUTES_PER_ENTRY = 25
LENGTH_BUCKETS = [300, 600, 1000, 1500, 2200]  # meters
MAX_ROUTE_SEGMENTS = 50  # Safety limit per route
MIN_ROUTE_LENGTH = 200  # meters

# Routing parameters (from §4.6)
LOCAL_ROAD_PROBABILITY = 0.15
HEADING_BONUS = 1.5
SHARP_TURN_PENALTY = 0.3
HEADING_PREFERENCE = 45  # degrees

# File paths
INPUT_PATH = Path(__file__).parent.parent / 'public' / 'assets' / 'road_segments_lion.json'
OUTPUT_PATH = Path(__file__).parent.parent / 'public' / 'assets' / 'route_cache.json'


# =============================================================================
# Helper Functions
# =============================================================================

def angle_difference(h1: float, h2: float) -> float:
    """Compute minimum angle difference between two headings."""
    diff = abs(h1 - h2)
    return min(diff, 360 - diff)


def compute_graph_version(segments: List[dict]) -> str:
    """Compute hash of segment structure for cache invalidation."""
    # Hash based on segment IDs and successor counts
    data = '|'.join(
        f"{s['id']}:{len(s.get('successors', []))}"
        for s in sorted(segments, key=lambda x: x['id'])
    )
    return hashlib.md5(data.encode()).hexdigest()[:12]


def score_successor(current: dict, candidate: dict) -> float:
    """
    Score a successor segment deterministically.
    Higher score = more likely to be selected.
    """
    score = 1.0

    # Heading preference
    heading_diff = angle_difference(
        current.get('endHeadingDeg', 0),
        candidate.get('startHeadingDeg', 0)
    )

    if heading_diff < HEADING_PREFERENCE:
        score *= HEADING_BONUS
    elif heading_diff > 90:
        score *= SHARP_TURN_PENALTY

    # Prefer faster segments (better flow)
    speed_ratio = candidate.get('speedRatio', 0.5)
    score *= (0.5 + speed_ratio)

    return score


def weighted_random_select(scored: List[Tuple[str, float]]) -> Optional[str]:
    """Select an ID from scored list using weighted random selection."""
    if not scored:
        return None

    total_weight = sum(s[1] for s in scored)
    if total_weight <= 0:
        return scored[random.randint(0, len(scored) - 1)][0]

    r = random.random() * total_weight
    cumulative = 0

    for seg_id, score in scored:
        cumulative += score
        if r < cumulative:
            return seg_id

    return scored[-1][0]


# =============================================================================
# Route Generation
# =============================================================================

def choose_next_segment(current: dict, segments: Dict[str, dict]) -> Optional[str]:
    """
    Choose next segment using routing logic from §4.6.
    Returns None if no valid successor.
    """
    successors = current.get('successors', [])
    if not successors:
        return None

    # Partition into major vs local
    major_successors = []
    local_successors = []

    for succ_id in successors:
        succ = segments.get(succ_id)
        if not succ:
            continue
        if succ.get('isMajor', False):
            major_successors.append(succ_id)
        else:
            local_successors.append(succ_id)

    # Choose which set to draw from
    candidates = major_successors
    if not major_successors:
        candidates = local_successors
    elif local_successors and random.random() < LOCAL_ROAD_PROBABILITY:
        candidates = local_successors

    if not candidates:
        candidates = successors

    # Score candidates deterministically
    scored = []
    for succ_id in candidates:
        succ = segments.get(succ_id)
        if succ:
            score = score_successor(current, succ)
            scored.append((succ_id, score))

    return weighted_random_select(scored)


def simulate_route(
    entry: dict,
    segments: Dict[str, dict],
    target_length: float
) -> Optional[dict]:
    """
    Simulate a route starting from entry segment.
    Returns RouteTemplate dict or None if route too short.
    """
    sequence = [entry['id']]
    cumulative_distances = [0, entry.get('lengthMeters', 0)]
    total_length = entry.get('lengthMeters', 0)
    current_segment = entry

    while total_length < target_length and len(sequence) < MAX_ROUTE_SEGMENTS:
        next_id = choose_next_segment(current_segment, segments)

        if not next_id:
            break  # Dead end

        next_segment = segments.get(next_id)
        if not next_segment:
            break

        sequence.append(next_id)
        total_length += next_segment.get('lengthMeters', 0)
        cumulative_distances.append(total_length)
        current_segment = next_segment

    if len(sequence) < 2 or total_length < MIN_ROUTE_LENGTH:
        return None

    return {
        'entrySegmentId': entry['id'],
        'segmentSequence': sequence,
        'totalLengthMeters': round(total_length, 2),
        'cumulativeDistances': [round(d, 2) for d in cumulative_distances],
    }


def generate_routes_for_entry(
    entry: dict,
    segments: Dict[str, dict],
    min_routes: int = ROUTES_PER_ENTRY
) -> List[dict]:
    """
    Generate routes for a single entry segment across all length buckets.
    Keeps trying until we have at least min_routes or hit max attempts.
    """
    routes = []
    max_attempts = min_routes * 3  # Allow retries for dead-end routes
    attempts = 0
    bucket_idx = 0

    while len(routes) < min_routes and attempts < max_attempts:
        target_length = LENGTH_BUCKETS[bucket_idx % len(LENGTH_BUCKETS)]
        route = simulate_route(entry, segments, target_length)

        if route:
            routes.append(route)

        attempts += 1
        bucket_idx += 1

    return routes


# =============================================================================
# Validation
# =============================================================================

def validate_route(route: dict, segments: Dict[str, dict]) -> bool:
    """Verify route connectivity is valid."""
    sequence = route.get('segmentSequence', [])

    for i in range(len(sequence) - 1):
        current = segments.get(sequence[i])
        if not current:
            return False

        next_id = sequence[i + 1]
        if next_id not in current.get('successors', []):
            return False

    return True


# =============================================================================
# Main
# =============================================================================

def main():
    print("=" * 60)
    print("ROUTE CACHE GENERATION")
    print("=" * 60)

    # Load input
    print(f"\nLoading {INPUT_PATH}...")
    with open(INPUT_PATH) as f:
        data = json.load(f)

    segments_list = data['segments']
    print(f"  Loaded {len(segments_list)} segments")

    # Build segment map
    segments: Dict[str, dict] = {s['id']: s for s in segments_list}

    # Find entry segments
    entry_segments = [s for s in segments_list if s.get('isEntry', False)]
    print(f"  Found {len(entry_segments)} entry segments")

    # Compute graph version
    graph_version = compute_graph_version(segments_list)
    print(f"  Graph version: {graph_version}")

    # Generate routes
    print("\nGenerating routes...")
    print(f"  Target: {ROUTES_PER_ENTRY} routes per entry")
    print(f"  Length buckets: {LENGTH_BUCKETS}")

    all_routes: Dict[str, List[dict]] = {}
    total_routes = 0
    entries_with_routes = 0
    entries_missing = 0

    for i, entry in enumerate(entry_segments):
        if (i + 1) % 100 == 0:
            print(f"  Processed {i + 1}/{len(entry_segments)} entries...")

        routes = generate_routes_for_entry(entry, segments)

        if routes:
            all_routes[entry['id']] = routes
            total_routes += len(routes)
            entries_with_routes += 1
        else:
            entries_missing += 1

    print(f"\n  Generated {total_routes} total routes")
    print(f"  {entries_with_routes} entries with routes")
    print(f"  {entries_missing} entries without routes")

    # Validate routes
    print("\nValidating routes...")
    valid_count = 0
    invalid_count = 0

    for entry_id, routes in all_routes.items():
        for route in routes:
            if validate_route(route, segments):
                valid_count += 1
            else:
                invalid_count += 1

    print(f"  {valid_count} valid routes")
    print(f"  {invalid_count} invalid routes")

    if invalid_count > 0:
        print("  ⚠️  WARNING: Some routes have connectivity issues")

    # Compute statistics
    all_lengths = []
    all_segment_counts = []

    for routes in all_routes.values():
        for route in routes:
            all_lengths.append(route['totalLengthMeters'])
            all_segment_counts.append(len(route['segmentSequence']))

    avg_length = sum(all_lengths) / len(all_lengths) if all_lengths else 0
    avg_segments = sum(all_segment_counts) / len(all_segment_counts) if all_segment_counts else 0

    # Build output
    output = {
        'meta': {
            'generatedAt': datetime.now().isoformat(),
            'routesPerEntry': ROUTES_PER_ENTRY,
            'totalRoutes': total_routes,
            'graphVersion': graph_version,
            'entryCount': len(entry_segments),
            'entriesWithRoutes': entries_with_routes,
            'avgRouteLength': round(avg_length, 2),
            'avgSegmentsPerRoute': round(avg_segments, 2),
            'lengthBuckets': LENGTH_BUCKETS,
        },
        'routes': all_routes,
    }

    # Write output
    print(f"\nWriting {OUTPUT_PATH}...")
    with open(OUTPUT_PATH, 'w') as f:
        json.dump(output, f)

    file_size = OUTPUT_PATH.stat().st_size / (1024 * 1024)
    print(f"  File size: {file_size:.2f} MB")

    # Summary
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"Entry segments:       {len(entry_segments)}")
    print(f"Entries with routes:  {entries_with_routes}")
    print(f"Total routes:         {total_routes}")
    print(f"Avg routes per entry: {total_routes / entries_with_routes:.1f}" if entries_with_routes else "N/A")
    print(f"Avg route length:     {avg_length:.1f} m")
    print(f"Avg segments/route:   {avg_segments:.1f}")
    print(f"Graph version:        {graph_version}")
    print("=" * 60)

    # Check acceptance criteria
    print("\nAcceptance Criteria:")
    routes_per_entry_ok = all(
        len(routes) >= 20
        for routes in all_routes.values()
    ) if all_routes else False
    print(f"  [{'✓' if routes_per_entry_ok else '✗'}] All entry segments have ≥20 routes")

    connectivity_ok = invalid_count == 0
    print(f"  [{'✓' if connectivity_ok else '✗'}] All routes pass connectivity check")

    has_version = bool(graph_version)
    print(f"  [{'✓' if has_version else '✗'}] Includes graph version hash")

    avg_length_ok = avg_length >= 500
    print(f"  [{'✓' if avg_length_ok else '✗'}] Average route length > 500m ({avg_length:.0f}m)")

    all_pass = routes_per_entry_ok and connectivity_ok and has_version and avg_length_ok
    print(f"\n{'✓ All criteria passed!' if all_pass else '✗ Some criteria failed'}")

    print("\nDone!")
    return 0 if all_pass else 1


if __name__ == '__main__':
    exit(main())
